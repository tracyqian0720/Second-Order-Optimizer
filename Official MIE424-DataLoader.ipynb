{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Fku1sV1uCrHs3-mosPq1HWD9r_JeXYCk","timestamp":1710535401244}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vaOaUZdwsJGn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710537506576,"user_tz":240,"elapsed":79216,"user":{"displayName":"Grant Lau","userId":"14881312612135011787"}},"outputId":"7a2023d1-df0e-4b6b-88f1-5f49c088b80b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Collecting pytorch-minimize\n","  Downloading pytorch_minimize-0.0.2-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-minimize) (1.25.2)\n","Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from pytorch-minimize) (1.11.4)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-minimize) (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch-minimize) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch-minimize) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch-minimize) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch-minimize) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch-minimize) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch-minimize) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch-minimize) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0->pytorch-minimize)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->pytorch-minimize) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->pytorch-minimize) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-minimize\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pytorch-minimize-0.0.2\n"]}],"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","#%pip install pytorch\n","%pip install pytorch-minimize"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch as pt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchmin import minimize\n","\n","import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","\n","class ChihuahuaMuffinDataset(Dataset):\n","    def __init__(self, directory, transform=None):\n","        self.directory = directory\n","        self.transform = transform\n","        self.labels = []\n","        self.images = []\n","        self.class_names = ['chihuahua', 'muffin']\n","\n","        for label in self.class_names:\n","            class_dir = os.path.join(self.directory, label)\n","            for img_file in os.listdir(class_dir):\n","                self.images.append(os.path.join(class_dir, img_file))\n","                self.labels.append(self.class_names.index(label))\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.images[idx]\n","        label = self.labels[idx]\n","        image = Image.open(image_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","!unzip -q \"/content/drive/My Drive/424 group project/dataset.zip\" -d \"/content/drive/My Drive/424 group project/dataset\"\n","\n","# Define transforms\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Assuming that `dataset` is the main directory containing train/val folders\n","train_directory = '/content/drive/My Drive/424 group project/dataset/train'\n","test_directory = '/content/drive/My Drive/424 group project/dataset/test'\n","\n","# Create dataset\n","train_dataset = ChihuahuaMuffinDataset(train_directory, transform=transform)\n","test_dataset = ChihuahuaMuffinDataset(test_directory, transform=transform)\n","\n","# Create data loader\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Example of iterating over the DataLoader\n","for images, labels in train_loader:\n","    # Here you would put your training code\n","    # This is just an example to show the data loading\n","    print(images.shape, labels.shape)"],"metadata":{"id":"u-wMyeLFuxEA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710538356159,"user_tz":240,"elapsed":201596,"user":{"displayName":"Grant Lau","userId":"14881312612135011787"}},"outputId":"131bd04f-41da-4fb5-a7e6-4561742e07e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([32, 3, 256, 256]) torch.Size([32])\n","torch.Size([29, 3, 256, 256]) torch.Size([29])\n"]}]},{"cell_type":"code","source":["!rm -rf \"/content/drive/My Drive/424 group project/dataset\""],"metadata":{"id":"mqtNjZw9Ax8n"},"execution_count":null,"outputs":[]}]}